# WGPT项目介绍

## 项目概述

WGPT（Web-based GPT）是一个综合性的网页应用，旨在通过集成多种GPT模型，为用户提供全面的办公、学习和数据分析解决方案。该项目不仅包括多样化的GPT模型应用，还计划纳入GLM4模型，以提高语言处理的效率和准确性。

## 数据库关系图和部分字段解释

![数据库关系图](./images/数据库关系字段解释.png)

## 后端与前端工作流程图

![前后端工作流程图](./images/关系图.png)

## 已完成的功能

- **登录系统**：提供安全且方便的用户登录功能。
- **流式输出**：sse的模式进行端口监听（openai好像就是用的sse，但是我也有写好socket的方式）
- **页面背景颜色调节**：允许用户根据个人喜好自定义页面背景颜色。
- **上下文管理**：有效处理和存储用户交互上下文。
- **文档传输**：支持在用户和系统间安全地传输文档。
- **GPTs API调用**：集成了多种第三方GPT模型API。
- **模型选择功能**：用户可根据需求选择不同的AI模型。
- **自动登录**：利用cookie实现便捷的自动登录功能。
- **后端安全控制**：实现用户权限和IP白名单管理。
- **实时更新用户余额**：动态显示用户的账户余额。

## 部署指南



### 获取源代码

```sh
git clone https://github.com/wlhtea/wlh_gpt.git
```

### 创建数据库

1. 创建名为`wgpt`的数据库，并在`init_sql.py`中配置数据库用户名和密码。

## 初始化

数据库初始化

```sh
python init_sql.py
```

## 安装依赖

```sh
pip install -r requirements.txt
```

## 启动后台

```sh
python openai_flask.py
```

## 本地运行

访问web.html即可在本地运行项目。

# 服务器部署

- 修改index 1.3.4.js中的URL地址，并确保服务器的5000端口已开放。
- 如js中url_base = 127.0.0.1:5000->你的ip地址:5000,有域名直接改为域名即可不需要加端口号

## GLM4与GPT3.5的对比

## GLM4的优势

- **响应速度**：GLM4提供更快的响应速度。
- **成本效益**：GLM4的费用相对较低，为0.1/1k token。
- **长文本支持**：支持128k上下文的长文本处理。

## GLM4的劣势

- **API文件传输限制**：目前仅支持JSON文件传输。
- **并发数量限制**：每时每刻最多5个并发请求。
- **数据库内容陈旧**：截至2021年，数据库内容相对陈旧。

## 使用GLM4的原因

- **成本效益**：GLM4为性价比较高的选择，特别是在处理非文档链接相关的任务时。
- **响应速度**：更快的响应时间，使得用户体验更为流畅。

## GPT4不可替代性

- **稳定性**：GPT4在处理文档链接和其他复杂内容方面表现更为稳定。
- **功能多样性**：适合处理多种类型的请求，包括链接内容获取和文档分析。
- **定制模型**：现在官方还没有GPTs的api接口文档，只能借助第三接口，通过在GPTs训练一个特殊情景的GPTs模型可提供给用户更加舒适和便利的体验，每次只要选择不同的场景后端调用对应场景的模型，即可满足用户的部分需求。
- **贵**：比GLM4贵两倍以上（现在99块钱1.8亿的token可以说贵百倍了，虽然有效期只有6个月）

## 未来规划

- **纳入GLM4模型**：提高语言处理的效率，同时降低运行成本。
- **增加用户注册和历史对话记录功能**：提升用户体验和功能完善性。
- **扩展页面功能**：如支持更丰富的文件上传的方式，当用户提供了较多文件可分批次进行上传，提高系统的灵活性和用户的便利性。
- **优化后端以支持OpenAI API**：为了更好地适应市场变化和技术进步，计划优化后端支持OpenAI的API（现在仍然使用第三方接口，测试起来费用较低）。
